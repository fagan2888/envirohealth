{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SEER Data Analysis\n",
    "# Phase 1: Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pandas.io import sql\n",
    "from MasterSeer import MasterSeer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The LoadSeerData class opens a connection to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LoadSeerData(MasterSeer):\n",
    "\n",
    "    def __init__(self, path=r'./data', reload=True, testMode=False, verbose=True, batch=10000):\n",
    "\n",
    "        # user supplied parameters\n",
    "        self.reload = reload        # deletes and recreates db before start of loading data.\n",
    "        self.testMode = testMode    # import one file, 100 records and return\n",
    "        self.verbose = verbose      # prints status messages\n",
    "        self.batchSize = batch      # number of rows to commit to db in one transation\n",
    "\n",
    "        if type(path) != str:\n",
    "            raise TypeError('path must be a string')\n",
    "\n",
    "        if path[-1] != '/':\n",
    "            path += '/'            # if path does not end with a backslash, add one\n",
    "\n",
    "        self.path = path\n",
    "\n",
    "        # open connection to the database\n",
    "        super().__init__(path, reload, testMode, verbose)\n",
    "        self.db_conn, self.db_cur = super().init_database(self.reload)\n",
    "        \n",
    "    def __del__(self):\n",
    "        self.db_conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The load_data function loads the SEER raw data into an sqlite3 database. The fname parameter is the path to the SEER data which supports a specific file or a wildcard filename to import all the data in one call. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def load_data(self, fname=r'incidence\\yr1973_2012.seer9\\breast.txt'):\n",
    "        \n",
    "        try:\n",
    "            self.dfDataDict = super().load_data_dictionary()\n",
    "        except Exception as e:\n",
    "            print('ERROR loading data dictionary.')\n",
    "            raise(e)\n",
    "\n",
    "        if len(self.dfDataDict) == 0:\n",
    "            raise('Bad Data Dictionary Data')\n",
    "\n",
    "        timeStart = time.perf_counter()\n",
    "\n",
    "        totRows = 0\n",
    "        for fileName in glob.glob(self.path + fname):\n",
    "            totRows += self.load_one_file(fileName)\n",
    "\n",
    "        if self.verbose:\n",
    "            print('Loading Data completed.\\n Rows Imported: {0:d} in {1:.1f} seconds.\\n Loaded {2:.1f} per sec.'.format\n",
    "                  (totRows, time.perf_counter() - timeStart, (totRows / (time.perf_counter() - timeStart))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The load_one_file function performs the sql inserts in the database. The fname parameter is the name of the individual SEER dataflie to import. The function then returns the number of rows inserted. The function also assigns column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    def load_one_file(self, fname):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('\\nStart Loading Data: {0}'.format(fname))\n",
    "\n",
    "        # Need to get the name of the SEER text file so we can store it into\n",
    "        # the SOURCE field.\n",
    "        fileSource = os.path.basename(fname)\n",
    "        fileSource = os.path.splitext(fileSource)[0]\n",
    "\n",
    "        try:\n",
    "            self.db_conn.execute('DROP TABLE {0}'.format(fileSource))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        colInfo = []  # hold start, stop byte offset for each field, used by read_fwf\n",
    "        for off, len in zip(self.dfDataDict.OFFSET, self.dfDataDict.LENGTH):\n",
    "            colInfo.append((off-1, off-1+len))\n",
    "\n",
    "        if self.verbose:\n",
    "            print('Starting read of raw data.')\n",
    "\n",
    "        dfData = pd.read_fwf(fname, colspecs = colInfo, header=None) #, nrows=100000) \n",
    "        #, nrows = self.batchSize, skiprows=totRows)\n",
    "\n",
    "        # assign column names\n",
    "        dfData.columns = self.dfDataDict.FIELD_NAME\n",
    "\n",
    "        if self.verbose:\n",
    "            print('Starting load of data to database.')\n",
    "\n",
    "        sql.to_sql(dfData, name=fileSource, con=self.db_conn, index=False, if_exists='append', \n",
    "                   chunksize=self.batchSize)\n",
    "\n",
    "        if self.verbose:\n",
    "            print('\\n - Loading completed. Rows Imported: {0:d}'.format(dfData.shape[0]))\n",
    "\n",
    "        return dfData.shape[0] # number of rows\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The create_table function creates and stores a table using the fields read from the data dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "    def create_table(self, tblName):\n",
    "        ''' Create the table from the fields read from data dictionary and stored in self.dataDictInfo\n",
    "            Make list comma delimited\n",
    "        '''\n",
    "\n",
    "        fieldList = self.dfDataDict.FIELD_NAME\n",
    "        delimList = ','.join(map(str, fieldList)) \n",
    "\n",
    "        # create the table\n",
    "        # SECURITY - Not subject to code injection even if Data Dictionary was\n",
    "        # hacked since create table is the command specified.\n",
    "        #            Not running any SELECT statements to hack.  Buffer\n",
    "        #            overflow problems mitigated with checks importing\n",
    "        #            dictionary.\n",
    "        self.db_conn.execute('CREATE TABLE {0:s}(SOURCE,'.format(tblName) + delimList + ')')\n",
    "                            \n",
    "    def __str__(self, **kwargs):\n",
    "        pass\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
